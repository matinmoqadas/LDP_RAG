# RAGâ€‘PipelineÂ ğŸš€

*A flexible, plugâ€‘andâ€‘play **Retrievalâ€‘Augmented Generation** evaluation harness*

<div align="center">

![Python](https://img.shields.io/badge/Python-3.9%2B-blue?logo=python)
![License](https://img.shields.io/badge/License-AddÂ YourÂ Own-lightgrey)
![Status](https://img.shields.io/badge/Build-passing-brightgreen)

</div>

---

## ğŸ“š Tableâ€¯ofâ€¯Contents

1. [Project layout](#-project-layout)
2. [Installation](#-installation)
3. [Environment variables](#-environment-variables)
4. [Quick start](#-quick-start)
5. [CLI reference](#-cli-reference)
6. [Output format](#-output-format)
7. [Extending the pipeline](#-extending-the-pipeline)
8. [Troubleshooting](#-troubleshooting)
9. [License](#-license)

---

## ğŸ“ Project layout

```text
project/
â”‚
â”œâ”€ models/                   # âœ each file defines ONE RAG class
â”‚   â”œâ”€ normal_rag.py         #   â€¢ NormalRAG
â”‚   â”œâ”€ privacy_gate_rag.py   #   â€¢ PrivacyGateRAG
â”‚   â”œâ”€ ldp_rag.py            #   â€¢ LDPRAG
â”‚   â””â”€ adaptive_rag.py       #   â€¢ AdaptiveRAG
â”‚
â”œâ”€ utils/
â”‚   â”œâ”€ metrics.py            # custom evaluation metrics
â”‚   â””â”€ adaptive_chunking.py  # AdaptiveChunkSplitter (or get_splitter())
â”‚
â”œâ”€ main.py                   # single CLI entryâ€‘point
â””â”€ README.md                 # youÂ areÂ here
```

```text
datasets/
â””â”€ dataset-ldp/
    â””â”€ Data_LDP/
        â”œâ”€ Docs/                    # knowledge base (.docx)
        â”œâ”€ Attack Question/         # prompts to ask the RAG
        â”‚   â”œâ”€ Customer Service/1.json â€¦ 10.json
        â”‚   â”œâ”€ Eâ€‘commerce/ â€¦
        â”‚   â””â”€ Healthcare/ â€¦
        â””â”€ MetaDatas/               # optional extras
```

---

## âš™ï¸ Installation

```bash
# create & activate virtualâ€‘env
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate

# core libraries
pip install -U pip wheel
pip install langchain faiss-cpu openai google-generativeai json5

# optional (pretty output inspection)
pip install pandas
```

> **PythonÂ 3.9Â or newer** is highly recommended (preâ€‘built FAISS wheels available).

---

## ğŸ”‘ Environment variables

| Variable         | Purpose                                             |
| ---------------- | --------------------------------------------------- |
| `OPENAI_API_KEY` | API key for GPTâ€‘style backâ€‘ends (e.g. AvalAI proxy) |
| `GOOGLE_API_KEY` | Only required when using Gemini RAG                 |

You can also override via `--api_key`/`--base_url` flags.

---

## ğŸƒâ€â™‚ï¸ Quick start

```bash
python main.py \
  --rag_type normal \
  --metrics faithfulness answer_relevancy \
  --adaptive_chunking \
  --output_path ./runs/demo.jsonl
```

**What happens?**

1. Buildsâ€¯/â€¯loads a FAISS index from `datasets/dataset-ldp/Data_LDP/Docs`.
2. Walks the entire *Attack Question* tree (`*.json` files).
3. For every question it:

   * retrieves `top_k` (defaultÂ **4**) relevant chunks,
   * generates an answer with the chosen RAG backâ€‘end,
   * evaluates requested metrics, and
   * writes one JSONâ€‘Lines record to `runs/demo.jsonl`.

---

## ğŸ’» CLI reference

| Flag                  | Default                                         | Description                                             |
| --------------------- | ----------------------------------------------- | ------------------------------------------------------- |
| `--rag_type`          | *(required)*                                    | `normal`, `privacy_gate`, `ldp`, `adaptive`             |
| `--docs_dir`          | `datasets/dataset-ldp/Data_LDP/Docs`            | Knowledgeâ€‘base folder                                   |
| `--questions_dir`     | `datasets/dataset-ldp/Data_LDP/Attack Question` | Prompts root                                            |
| `--metrics`           | â€”                                               | Spaceâ€‘separated list from `utils.metrics`               |
| `--adaptive_chunking` | `false`                                         | Toggle `utils.adaptive_chunking.AdaptiveChunkSplitter`  |
| `--output_path`       | *(required)*                                    | Destination `.jsonl` file                               |
| `--index_name`        | `faiss_index`                                   | Subâ€‘folder in `RAG_Database/`                           |
| `--top_k`             | `4`                                             | Context chunks to retrieve                              |
| LLM flags             | â€”                                               | `--llm_name`, `--model_name`, `--api_key`, `--base_url` |

---

## ğŸ“„ Output format

Every **line** in the output file is a selfâ€‘contained JSON object:

```jsonc
{
  "question": "How would this medical detail impact treatment plansÂ â€¦?",
  "question_type": "Healthcare",
  "label": "Sensitive",
  "source_sentence": "CKD increases the risk of cardiovascular disease,Â â€¦",
  "answer": "First, clinicians wouldÂ â€¦",
  "metrics": {
    "faithfulness": 0.93,
    "answer_relevancy": 0.82
  },
  "file": "/â€¦/Attack Question/Healthcare/7.json"
}
```

```python
import pandas as pd
df = pd.read_json("runs/demo.jsonl", lines=True)
```

---

## ğŸ”Œ Extending the pipeline

| Task                       | How                                                                                                                        |
| -------------------------- | -------------------------------------------------------------------------------------------------------------------------- |
| **Add a new RAG backâ€‘end** | 1) Create `models/my_rag.py` exposing one class â€   2) Register in `RAG_CLASS_REGISTRY` â†’ `"my_rag": "models.my_rag:MyRAG"` |
| **Add a metric**           | Implement a function in `utils/metrics.py`, then call `--metrics my_metric`.                                               |
| **Custom chunker**         | Expose `AdaptiveChunkSplitter` or `get_splitter()` in `utils/adaptive_chunking.py`; enable with `--adaptive_chunking`.     |

â€ Â Class must provide `.load_documents()`, `.save_vector_store()`, `.load_vector_store()`, and `.generate()`.

---

## ğŸ› Troubleshooting

| Symptom                      | Remedy                                              |
| ---------------------------- | --------------------------------------------------- |
| `ModuleNotFoundError: faiss` | `pip install faiss-cpu` *(or* `faiss-gpu`*)*        |
| 401 / 403 from LLM           | Check `OPENAI_API_KEY` and `--base_url`             |
| â€œNo documents loaded yetâ€    | Ensure `.docx` files actually exist in `--docs_dir` |
| Metric `KeyError`            | Verify the metric name passed in `--metrics`        |

---

## ğŸ“œ License

Add your license text here.

---

> Made with â¤ï¸Â &Â LangChain.  Happy experimenting!
